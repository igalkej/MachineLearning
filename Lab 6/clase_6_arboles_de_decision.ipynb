{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Aprendizaje Automático** - 2023\n",
        "# Clase 6: Árboles de Decisión (CARTs)\n",
        "\n",
        "*Trabajaron en esta notebook: Sofia Del Pozo, Diego Onna, Gaston Bujia*"
      ],
      "metadata": {
        "id": "whc8bN5Vn3W8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Contenidos\n",
        "\n",
        "* Árboles de clasificación\n",
        "* Árboles de regresión\n",
        "* Desbalance de clases"
      ],
      "metadata": {
        "id": "0xljijnu-0Eh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Arboles de Decisión: La forma fácil\n",
        "\n",
        "Scikit-Learn nos provee el módulo [Tree](https://scikit-learn.org/stable/modules/tree.html) en el cuál encontraremos los CARTs: *Classification And Regression Trees*. En esta notebook veremos como ajustar un árbol de decisión para [clasificación](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier), sus hiperparámetros y las regiones de decisión."
      ],
      "metadata": {
        "id": "6bUAsnqyyeQa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset\n",
        "\n",
        "Para probar los árboles usaremos dos datasets que crearemos: [moons](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_moons.html) y [circles](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_circles.html). También utilizaremos [blobs](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_blobs.html) que nos permite generar distribuciones Gaussianas."
      ],
      "metadata": {
        "id": "gI9SnLME229y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_moons, make_blobs, make_circles\n",
        "from sklearn.dummy import DummyClassifier"
      ],
      "metadata": {
        "id": "aF5a_wDIkjj-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear dataset con make_moons\n",
        "X_moons, y_moons = make_moons(n_samples=1000, noise=0.1, random_state=42)\n",
        "\n",
        "# Crear dataset con make_circles\n",
        "X_circles, y_circles = make_circles(n_samples=1000, noise=0.1, factor=0.5, random_state=42)\n",
        "\n",
        "# Visualizar ambos datasets\n",
        "fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(11, 5))\n",
        "\n",
        "ax1.scatter(X_moons[:, 0], X_moons[:, 1], c=y_moons, cmap='viridis')\n",
        "ax1.set_title('make_moons dataset')\n",
        "\n",
        "ax2.scatter(X_circles[:, 0], X_circles[:, 1], c=y_circles, cmap='viridis')\n",
        "ax2.set_title('make_circles dataset')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3e-H9GdnJjGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Separamos los datos en conjuntos de entrenamiento y testeo"
      ],
      "metadata": {
        "id": "TlhiKI5Twzr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Separar los datos en train y test para make_moons\n",
        "X_train_moons, X_test_moons, y_train_moons, y_test_moons = train_test_split(X_moons, y_moons, test_size=0.3, random_state=42)\n",
        "\n",
        "# Separar los datos en train y test para make_circles\n",
        "X_train_circles, X_test_circles, y_train_circles, y_test_circles = train_test_split(X_circles, y_circles, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "cyo_5gajwz83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Profundidad de los árboles"
      ],
      "metadata": {
        "id": "zvmmitAKlgV9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dados estos dos datasets, probaremos en ambos dos árboles diferentes, uno con una profundidad pequeña: `max_depth=2` y otro con una profundidad mayor `max_depth=10`. El objetivo es entender cómo se comportar para una tarea de clasificación y ver las limitaciones.\n",
        "\n",
        "Los CARTs, como casi todo modelo en scikit-learn, se los utiliza de la misma manera:\n",
        "1.  Se instancia un modelo, pasándole sus parámetros.\n",
        "2.  Se ajusta/entrena el modelo mediante el método fit, el cual recibe los datos de entrada y el target\n",
        "3.  Se predice sobre nuevos datos utilizando el método predict\n",
        "4.  Se evalua la performance utilizando metricas en el modulo sklearn.metric"
      ],
      "metadata": {
        "id": "KiVFGWy71BcL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciar árbol de clasificación profundo para make_moons\n",
        "tree_deep_moons = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
        "\n",
        "# Instanciar árbol de clasificación no tan profundo para make_moons\n",
        "tree_shallow_moons = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
        "\n",
        "# Fit de los árboles en make_moons\n",
        "tree_deep_moons.fit(X_train_moons, y_train_moons)"
      ],
      "metadata": {
        "id": "1uI0R4b91EGg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree_shallow_moons.fit(X_train_moons, y_train_moons)"
      ],
      "metadata": {
        "id": "Yy8HSJkiwq7Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instanciar árbol de clasificación profundo para make_circles\n",
        "tree_deep_circles = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
        "\n",
        "# Instanciar árbol de clasificación no tan profundo para make_circles\n",
        "tree_shallow_circles = DecisionTreeClassifier(max_depth=2, random_state=42)\n",
        "\n",
        "# Fit de los árboles en make_circles\n",
        "tree_deep_circles.fit(X_train_circles, y_train_circles)"
      ],
      "metadata": {
        "id": "QKqoiu4VwhIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree_shallow_circles.fit(X_train_circles, y_train_circles)"
      ],
      "metadata": {
        "id": "JLNZW7ZowtGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluación"
      ],
      "metadata": {
        "id": "HyeEhrttQh81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicciones en make_moons\n",
        "y_pred_deep_moons = tree_deep_moons.predict(X_test_moons)\n",
        "y_pred_shallow_moons = tree_shallow_moons.predict(X_test_moons)\n",
        "\n",
        "# Accuracy en make_moons\n",
        "acc_deep_moons = accuracy_score(y_test_moons, y_pred_deep_moons)\n",
        "acc_shallow_moons = accuracy_score(y_test_moons, y_pred_shallow_moons)\n",
        "\n",
        "# Predicciones en make_circles\n",
        "y_pred_deep_circles = tree_deep_circles.predict(X_test_circles)\n",
        "y_pred_shallow_circles = tree_shallow_circles.predict(X_test_circles)\n",
        "\n",
        "# Accuracy en make_circles\n",
        "acc_deep_circles = accuracy_score(y_test_circles, y_pred_deep_circles)\n",
        "acc_shallow_circles = accuracy_score(y_test_circles, y_pred_shallow_circles)\n",
        "\n",
        "print(f\"Accuracy con árbol profundo en make_moons: {acc_deep_moons}\")\n",
        "print(f\"Accuracy con árbol profundo en make_circles: {acc_deep_circles}\")\n",
        "print(f\"Accuracy con árbol no tan profundo en make_moons: {acc_shallow_moons}\")\n",
        "print(f\"Accuracy con árbol no tan profundo en make_circles: {acc_shallow_circles}\")\n"
      ],
      "metadata": {
        "id": "vsUagpLJjhAY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualización"
      ],
      "metadata": {
        "id": "rVmXENAH2zhp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Frontera de decisión"
      ],
      "metadata": {
        "id": "AVOD-Uw2N3Po"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Nos armamos una función auxiliar para graficar las regiones de decisión de un clasificador\n",
        "def plot_decision_regions(X, y, classifier, ax):\n",
        "    # Configurar grilla\n",
        "    h = 0.02\n",
        "    x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
        "    y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
        "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
        "\n",
        "    # Predecir clases para cada punto en la grilla\n",
        "    Z = classifier.predict(np.c_[xx.ravel(), yy.ravel()])\n",
        "    Z = Z.reshape(xx.shape)\n",
        "\n",
        "    # Graficar regiones de decisión y puntos de entrenamiento\n",
        "    ax.contourf(xx, yy, Z, cmap=plt.cm.RdYlBu, alpha=0.5)\n",
        "    ax.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.RdYlBu, edgecolors='black')\n",
        "\n",
        "# Graficar regiones de decisión de ambos árboles en ambos datasets\n",
        "fig, axs = plt.subplots(nrows=2, ncols=2, figsize=(10, 8))\n",
        "axs[0, 0].set_title(\"Árbol profundo en make_moons\")\n",
        "plot_decision_regions(X_moons, y_moons, tree_deep_moons, axs[0, 0])\n",
        "axs[0, 1].set_title(\"Árbol no tan profundo en make_moons\")\n",
        "plot_decision_regions(X_moons, y_moons, tree_shallow_moons, axs[0, 1])\n",
        "axs[1, 0].set_title(\"Árbol profundo en make_circles\")\n",
        "plot_decision_regions(X_circles, y_circles, tree_deep_circles, axs[1, 0])\n",
        "axs[1, 1].set_title(\"Árbol no tan profundo en make_circles\")\n",
        "plot_decision_regions(X_circles, y_circles, tree_shallow_circles, axs[1, 1])\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "6Vlx-jPYLg2P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cosas a tener en cuenta\n",
        "\n",
        "* Las fronteras de decisión son ortogonales (solo puede dividir con rectas a 90° entre si).\n",
        "* Un árbol lo suficientemente profundo podría aproximar *cualquier función matemática* (de las normalitas)\n",
        "* Modelo más complejo != Modelo que mejor generaliza\n",
        "* Trabajamos en 2D para poder visualizar las cosas, pero en la práctica, el número de dimensiones, que equivale al número de atributos usados, es mucho mayor a lo que podemos observar.\n",
        "\n",
        "![alt text](https://pbs.twimg.com/media/Dtq79-1X4AA7lJW.jpg)\n",
        "\n",
        "(Si no saben quien es [Geoffrey Hinton](https://en.wikipedia.org/wiki/Geoffrey_Hinton), deberían ya que lo llaman [el padrino del Deep Learning](https://www.youtube.com/watch?v=-eyhCTvrEtE&ab_channel=PreserveKnowledge))"
      ],
      "metadata": {
        "id": "ZaoUTYH5_EwG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decisiones del árbol\n",
        "\n",
        "Podemos tratar de visualizar el árbol y las consiguientes decisiones usando la función [`plot_tree`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html#sklearn.tree.plot_tree) de sklearn ([documentación extra](https://scikit-learn.org/stable/modules/tree.html#classification))."
      ],
      "metadata": {
        "id": "1UeW8MyDNo5x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import plot_tree\n",
        "plot_tree(tree_shallow_moons);"
      ],
      "metadata": {
        "id": "NzQN3azmyI8n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_tree(tree_deep_moons);"
      ],
      "metadata": {
        "id": "HgTfZ_FsGABz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Por qué no es un árbol simétrico como en el anterior caso? (Tip: Analizar cada hoja!)"
      ],
      "metadata": {
        "id": "YpUv-H-gGFVF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "También podemos utilizar algunas librerias auxiliares para visualizar el modelo e incluso exportarlo usando [export_graphviz](https://scikit-learn.org/stable/modules/generated/sklearn.tree.export_graphviz.html#sklearn.tree.export_graphviz). ¿Identifican que nodos son las hojas(nodos terminales que no se dividen)? ¿Qué información les brinda cada nodo?"
      ],
      "metadata": {
        "id": "r8QjmM5eyYyH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from six import StringIO  \n",
        "from IPython.display import Image  \n",
        "from sklearn.tree import export_graphviz\n",
        "import pydotplus\n",
        "\n",
        "dot_data = StringIO()\n",
        "export_graphviz(tree_deep_moons, \n",
        "                out_file=dot_data,  \n",
        "                filled=True,\n",
        "                rounded=True)\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "Image(graph.create_png())"
      ],
      "metadata": {
        "id": "77lOL08e3lsQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio \n",
        "\n",
        "1. Para este ejercicio deberan instanciar un nuevo dataset de `make_moons` con 1000 puntos y `noise=0.2`. Realizar una división de datos en `train` y `test`.\n",
        "2. Instanciar y entrenar 20 arboles diferentes usando los mismos hiperparametros pero con profundidad de 1 a 20.\n",
        "3. Graficar el accuracy de estos arboles en ambos conjuntos con la profundidad en el eje `x` y accuracy en el eje `y`. ¿A partir de que punto dirían que el arbol esta sobreajustando?\n",
        "4. Grafique el mejor árbol encontrado."
      ],
      "metadata": {
        "id": "d-ELEUIfSLaq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nOK6CvypJksW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hiperparámetros - Random Search\n",
        "\n",
        "Los árboles cuentan con muchos hiperparámetros para elegir, lo cuál los hace muy versátiles pero tienen una gran tendencia a *overfitear* los datos. Muchos de estos hiperparámetros tienen como objetivo controlar la complejidad del modelo y evitar asi el overfitting. Algunos de los más importantes implementados en scikit-learn son los siguientes:\n",
        "\n",
        "1. `criterion`: la función de calidad utilizada para evaluar la calidad de una división. Las opciones son \"gini\" para la impureza de Gini y \"entropy\" para la ganancia de información.\n",
        "\n",
        "2. `max_depth`: la profundidad máxima del árbol. Este hiperparámetro controla la complejidad del modelo y puede evitar el sobreajuste.\n",
        "\n",
        "3. `min_samples_split`: el número mínimo de muestras requeridas para dividir un nodo interno. Si el número de muestras en un nodo es menor que este valor, no se realizará la división.\n",
        "\n",
        "4. `min_samples_leaf`: el número mínimo de muestras requeridas para ser una hoja. Si la cantidad de muestras en un nodo es menor que este valor después de la división, el nodo será considerado una hoja.\n",
        "\n",
        "5. `max_features`: el número máximo de características a considerar al buscar la mejor división. Si es None, se consideran todas las características.\n",
        "\n",
        "6. `ccp_alpha`: un parámetro de complejidad efectiva que penaliza árboles con muchas ramas. Este parámetro controla la cantidad de poda que se realiza en el árbol. Un valor más alto de ccp_alpha aumenta la cantidad de poda y puede reducir el sobreajuste.\n",
        "\n",
        "Una mención extra para el `class_weight` que lo verán en la parte de desbalance."
      ],
      "metadata": {
        "id": "EVNSMLxd26Z3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dado que son muchos hiperparamentros es necesario un método para optimizar la búsqueda de la combinación optima. Una forma es utilizando [RandomizedSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html) que es un método de búsqueda de hiperparámetros que en lugar de probar todas las posibles combinaciones, este método elige aleatoriamente un subconjunto de combinaciones para evaluar, lo que lo hace más eficiente en términos de tiempo y recursos.\n",
        "\n"
      ],
      "metadata": {
        "id": "MB0C6FXULgMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint, expon\n",
        "\n",
        "# Definir el modelo de árbol de decisión\n",
        "modelo_a_optimizar = DecisionTreeClassifier()\n",
        "\n",
        "# Definir el espacio de búsqueda de los hiperparámetros\n",
        "param_dist = {'criterion': [\"gini\", \"entropy\"],\n",
        "              'max_depth': [3, 5, 7, 10, None],\n",
        "              'max_features': randint(1, 4),\n",
        "              'min_samples_split': randint(2, 11),\n",
        "              'min_samples_leaf': randint(1, 11),\n",
        "              'ccp_alpha': expon(scale=0.1)}\n",
        "\n",
        "# Definir la métrica de evaluación\n",
        "metric = 'accuracy'\n",
        "\n",
        "# Definir el objeto de búsqueda aleatoria\n",
        "search = RandomizedSearchCV(modelo_a_optimizar, param_distributions=param_dist, n_iter=100, cv=5, scoring=metric)\n",
        "\n",
        "# Entrenar el modelo con la búsqueda aleatoria de hiperparámetros\n",
        "search.fit(X_train_moons, y_train_moons)\n",
        "\n",
        "# Obtener los hiperparámetros óptimos\n",
        "print(\"Mejores hiperparámetros:\", search.best_params_)\n",
        "\n",
        "# Evaluar el modelo con los hiperparámetros óptimos en el conjunto de prueba\n",
        "accuracy = search.score(X_test_moons, y_test_moons)\n",
        "print(\"Precisión del modelo:\", accuracy)"
      ],
      "metadata": {
        "id": "-KvNbHZR3mHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Ejercicio** - Haga una búsqueda de hiperparámetros para el conjunto de círculos. Explore los hiperparámetros mencionados."
      ],
      "metadata": {
        "id": "Ncps5lmGOmkn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lKgF8nE4OuAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Arboles de regresión\n",
        "\n",
        "Scikit-Learn también tiene implementados [árboles de regresión](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html). El árbol de regresión `DecisionTreeRegressor` es una variante del árbol de decisión que se utiliza para problemas de regresión en lugar de clasificación. En lugar de clasificar las muestras en diferentes categorías, el árbol de regresión realiza una predicción numérica del valor de salida para cada muestra.\n",
        "\n",
        "Al igual que con el árbol de decisión para clasificación, los hiperparámetros del árbol de regresión, como `max_depth`, `min_samples_split`, `min_samples_leaf`, `max_features`, `criterion`, `ccp_alpha`, entre otros, pueden ser ajustados para controlar la complejidad del modelo y evitar el sobreajuste."
      ],
      "metadata": {
        "id": "U_XDx-aT3qwv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Desbalance de clases\n",
        "\n",
        "El desbalance de clases en la clasificación es un problema común que puede afectar significativamente el rendimiento del modelo. Ocurre cuando la proporción de ejemplos en una clase es mucho menor que en las otras, lo que puede hacer que el modelo esté sesgado hacia la clase mayoritaria y tenga dificultades para reconocer la clase minoritaria. Como resultado, la precisión de la predicción en la clase minoritaria puede ser baja, lo que puede ser problemático en aplicaciones donde la identificación de la clase minoritaria es crucial. Trabajemos un poco con el tema.\n",
        "\n",
        "Primero creemos un data set que sea desbalanceado."
      ],
      "metadata": {
        "id": "2s3s87b0xnQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_desbal, y_desbal = make_circles(n_samples=[950, 50], noise=0.1, shuffle=False, random_state=42)\n",
        "plt.scatter(X_desbal[:, 0], X_desbal[:, 1], c=y_desbal, cmap='viridis')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "u9_T3AfdWCSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo 1"
      ],
      "metadata": {
        "id": "eiTZhA_1zyhx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_desbal, X_test_desbal, y_train_desbal, y_test_desbal = train_test_split(X_desbal,y_desbal, shuffle=False)\n",
        "X_train_desbal.shape, X_test_desbal.shape"
      ],
      "metadata": {
        "id": "jtu8xayWxo-Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = DecisionTreeClassifier(max_depth=10, random_state=42)\n",
        "\n",
        "# Entrenamos\n",
        "model.fit(X_train_desbal, y_train_desbal)\n",
        "\n",
        "print(f\"Accuracy en train: {accuracy_score(y_train_desbal, model.predict(X_train_desbal))}\")\n",
        "print(f\"Accuracy en test: {accuracy_score(y_test_desbal, model.predict(X_test_desbal))}\")"
      ],
      "metadata": {
        "id": "GDUdJNo2XATT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "¿Qué les parece que sucede con las metricas de accuracy? *Hint:* Observen que sucede con los tamaños de train y test."
      ],
      "metadata": {
        "id": "GCENlyP105TI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Para ayudar a responder esa pregunta podemos graficar el modelo y sus fronteras de decisión\n",
        "#fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(8, 6))\n",
        "#plot_decision_regions(X_train_desbal, y_train_desbal, model, axs)"
      ],
      "metadata": {
        "id": "18IO7j0RzDPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(y_test_desbal,model.predict(X_test_desbal)), annot=True, annot_kws={\"size\": 16})"
      ],
      "metadata": {
        "id": "aKOZcAHCpv83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un opción para atacar este problema es utilizar los hiperparámetros de *shuffle* y *stratify* de [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)."
      ],
      "metadata": {
        "id": "lpr9LYVSSEg2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Repetir el split utilizando en el split shuffle y stratify y generar un nuevo modelo\n",
        "# COMPLETAR"
      ],
      "metadata": {
        "id": "B-QHwICPz49I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo 2\n",
        "\n",
        "¿Qué pasa con el accuracy cuando hay desbalance? Vamos a comparar un árbol de decisión con un [DummyClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.dummy.DummyClassifier.html) para entender cómo el desbalance puede afectar la clasificación."
      ],
      "metadata": {
        "id": "SIAGzPODz-RH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_desbal,y_desbal, stratify=y_desbal)\n",
        "\n",
        "mi_arbolito = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
        "mi_otro_modelito = DummyClassifier(strategy='most_frequent')\n",
        "\n",
        "# Entrenamos ambos modelos\n",
        "mi_arbolito.fit(X_train, y_train)\n",
        "mi_otro_modelito.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Accuracy en test del arbol: {accuracy_score(y_test, mi_arbolito.predict(X_test))}\")\n",
        "print(f\"Accuracy en test del otro modelito: {accuracy_score(y_test, mi_otro_modelito.predict(X_test))}\")"
      ],
      "metadata": {
        "id": "omV7VnKWqJrD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, mi_arbolito.predict(X_test)))"
      ],
      "metadata": {
        "id": "ZJEt7euM43eB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(y_test,mi_arbolito.predict(X_test)), annot=True, annot_kws={\"size\": 16})"
      ],
      "metadata": {
        "id": "s7MpSNkZ3QkT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, mi_otro_modelito.predict(X_test)))"
      ],
      "metadata": {
        "id": "aK5cgSa55Fua"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.heatmap(confusion_matrix(y_test,mi_otro_modelito.predict(X_test)), annot=True, annot_kws={\"size\": 16})"
      ],
      "metadata": {
        "id": "JUhEtdD93Tj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ĺos árboles de decisión nos permiten tener en cuenta el desbalance a partir de darle a cada instancia un peso relativo a su distribución, es decir, clasificar bien una clase más infrecuente pesa más que una clase muy frecuente. Para eso existe el hiperparámetro `class_weight`."
      ],
      "metadata": {
        "id": "qAGSn6ZuTg6w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mi_arbolito_balanceado = DecisionTreeClassifier(max_depth=5, class_weight=\"balanced\", random_state=42)\n",
        "\n",
        "mi_arbolito_balanceado.fit(X_train, y_train)\n",
        "\n",
        "print(f\"Accuracy en test del arbol sin balancear: {accuracy_score(y_test, mi_arbolito.predict(X_test))}\")\n",
        "print(f\"Accuracy en test del arbol balanceado: {accuracy_score(y_test, mi_arbolito_balanceado.predict(X_test))}\")"
      ],
      "metadata": {
        "id": "xMH-xOa64X-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora el árbol balanceado consideró que cada clasificar bien cada muestra no es lo mismo, entonces nos devuelve una métrica más realista que es el *balanced accuracy*: [documentación](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html)."
      ],
      "metadata": {
        "id": "lQIhV-OAoZrs"
      }
    }
  ]
}